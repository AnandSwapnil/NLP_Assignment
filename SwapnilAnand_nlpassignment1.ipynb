{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### NLP Assignment-1"
      ],
      "metadata": {
        "id": "XSzrJmwX30Yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.To run the code we can execute it cell by cell or Run all can also be used.  \n",
        "\n",
        "2.It is Multilabel classification problem and macro F1 score is used for evaluation.\n",
        "\n",
        "3.Many models executed are commented.We can try out by uncommenting them and comparing there scores."
      ],
      "metadata": {
        "id": "FhfvO13a1bNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "tEgtwGg233gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/train_split.csv\n",
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/test_split.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4KpW8S4eONm",
        "outputId": "ec1af9f6-fd24-440e-db9a-779500bf7d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-25 14:10:14--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/train_split.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 144474 (141K) [text/plain]\n",
            "Saving to: ‘train_split.csv.1’\n",
            "\n",
            "\rtrain_split.csv.1     0%[                    ]       0  --.-KB/s               \rtrain_split.csv.1   100%[===================>] 141.09K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-09-25 14:10:14 (6.12 MB/s) - ‘train_split.csv.1’ saved [144474/144474]\n",
            "\n",
            "--2024-09-25 14:10:14--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/test_split.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35259 (34K) [text/plain]\n",
            "Saving to: ‘test_split.csv.1’\n",
            "\n",
            "test_split.csv.1    100%[===================>]  34.43K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-09-25 14:10:14 (4.52 MB/s) - ‘test_split.csv.1’ saved [35259/35259]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install pandas scikit-learn\n",
        "!pip install nltk\n",
        "\n"
      ],
      "metadata": {
        "id": "Q69gdda13sAz",
        "outputId": "7e7c1ba5-fd4d-4747-e423-70f7caea4f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries and Create Data Frame\n"
      ],
      "metadata": {
        "id": "FZLI4PTzcGfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score\n",
        "import re\n",
        "\n",
        "train = pd.read_csv('/content/train_split.csv')\n",
        "test = pd.read_csv('/content/test_split.csv')\n",
        "\n",
        "print(train.head())\n",
        "print(test.head())\n",
        "\n",
        "\n",
        "X_train = train['text']\n",
        "y_train = train[['Joy', 'Fear', 'Anger', 'Sadness', 'Surprise']]\n",
        "X_test = test['text']\n",
        "y_test = test[['Joy', 'Fear', 'Anger', 'Sadness', 'Surprise']]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sZF3kyV5vWaN",
        "outputId": "bcd3999a-ee29-4e2e-be02-e0830661dd08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  Joy  Fear  Anger  \\\n",
            "0  The light would come all the way up to your ve...    0     1      0   \n",
            "1                   Well, my birthday is in January.    0     0      0   \n",
            "2  Tears in my eyes, too much on my mind, and dee...    0     1      0   \n",
            "3  My eyes scanned quickly into every room, every...    0     1      1   \n",
            "4  I felt the afterglow of the late afternoon sun...    1     0      0   \n",
            "\n",
            "   Sadness  Surprise  \n",
            "0        0         1  \n",
            "1        0         0  \n",
            "2        1         0  \n",
            "3        0         0  \n",
            "4        0         0  \n",
            "                                                text  Joy  Fear  Anger  \\\n",
            "0  And they probably knew exactly what your dad saw.    0     1      0   \n",
            "1  My neck still hurts while I'm working, and I w...    0     1      1   \n",
            "2  and Christian fish bumper stickers, it caught ...    1     0      0   \n",
            "3                               It felt so unreal...    0     1      0   \n",
            "4  ' To be honest I don't know why I set out into...    0     1      0   \n",
            "\n",
            "   Sadness  Surprise  \n",
            "0        0         1  \n",
            "1        0         0  \n",
            "2        0         1  \n",
            "3        0         1  \n",
            "4        0         0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "\n",
        "# Regular expressions\n",
        "def extract_sentiment_keywords(text):\n",
        "    sentiment = {'Joy': 0, 'Fear': 0, 'Anger': 0, 'Sadness': 0, 'Surprise': 0}\n",
        "\n",
        "    patterns = {\n",
        "        'Joy': r'\\b(?:[hH]app(?:y|iness|ily|ier|iest)?|[jJ]oy(?:ous|ful|fully)?|[eE]xcite(?:d|ment|s)?|[eE]lat(?:ed|ion)?|[pP]leas(?:ed|ure|ing)?|[dD]elight(?:ed|ful)?)\\b',\n",
        "        'Fear': r'\\b(?:[fF]ear(?:ful|ing)?|[sS]care(?:d|y|s)?|[tT]errifi(?:ed|ing|es)?|[aA]fraid|worri(?:ed|es|some|ing)?)|[dD]ie|[dD]eath\\b',\n",
        "        'Anger': r'\\b(?:[aA]ngr(?:y|ier|iest|ily)?|[mM]ad(?:ness)?|[fF]uri(?:ous|osity)?|[iI]rat(?:e|ion)?|[rR]esent(?:ful|ment)?)\\b',\n",
        "        'Sadness': r'\\b(?:[sS]ad(?:ness|den|dest)?|[uU]nhapp(?:y|iness)?|[dD]epress(?:ed|ion)?|[mM]ourn(?:ful|ing)?|[gG]rief|[tT]ear(?:s|ful)?|[dD]ie|[dD]eath)\\b',\n",
        "        'Surprise': r'\\b(?:[sS]urpris(?:ed|ing|es)?|[aA]maz(?:ed|ing|ement)?|[aA]stonish(?:ed|ing|ment)?|[sS]hock(?:ed|ing|s)?)\\b',\n",
        "    }\n",
        "\n",
        "    for sentiment_type, pattern in patterns.items():\n",
        "        if re.search(pattern, text, re.IGNORECASE):\n",
        "            sentiment[sentiment_type] = 1\n",
        "    return pd.Series(sentiment)\n",
        "\n",
        "\n",
        "X_train_reg = X_train.apply(extract_sentiment_keywords)\n",
        "X_test_reg = X_test.apply(extract_sentiment_keywords)\n",
        "\n",
        "\n",
        "ngram_vectorizer = CountVectorizer(ngram_range=(1, 3), stop_words='english')\n",
        "\n",
        "X_train_ngrams = ngram_vectorizer.fit_transform(X_train)\n",
        "X_test_ngrams = ngram_vectorizer.transform(X_test)\n",
        "\n",
        "# Convert n-gram features to DataFrame\n",
        "ngram_features_train = pd.DataFrame(X_train_ngrams.toarray(), columns=ngram_vectorizer.get_feature_names_out())\n",
        "ngram_features_test = pd.DataFrame(X_test_ngrams.toarray(), columns=ngram_vectorizer.get_feature_names_out())\n",
        "\n",
        "\n",
        "X_train_combined = pd.concat([X_train_reg.reset_index(drop=True), ngram_features_train.reset_index(drop=True)], axis=1)\n",
        "X_test_combined = pd.concat([X_test_reg.reset_index(drop=True), ngram_features_test.reset_index(drop=True)], axis=1)\n",
        "\n",
        "print(X_train_combined)\n",
        "print(X_test_combined)\n",
        "\n",
        "model = OneVsRestClassifier(LogisticRegression())\n",
        "\n",
        "\n",
        "model.fit(X_train_combined, y_train)\n",
        "\n",
        "\n",
        "y_pred_test_combined = model.predict(X_test_combined)\n",
        "\n",
        "# F1 score\n",
        "def evaluate(y_true, y_pred):\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    print(f\"F1 Score (macro):\", f1)\n",
        "\n",
        "\n",
        "evaluate(y_test, y_pred_test_combined)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXKHYOuD88Eb",
        "outputId": "afbce2e4-8d38-4bb7-daa8-7128432678be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Joy  Fear  Anger  Sadness  Surprise  00  00 started  00 started losing  \\\n",
            "0       0     0      0        0         0   0           0                  0   \n",
            "1       0     0      0        0         0   0           0                  0   \n",
            "2       0     0      0        1         0   0           0                  0   \n",
            "3       0     0      0        0         0   0           0                  0   \n",
            "4       0     0      0        0         0   0           0                  0   \n",
            "...   ...   ...    ...      ...       ...  ..         ...                ...   \n",
            "1595    0     0      0        0         0   0           0                  0   \n",
            "1596    0     0      0        0         0   0           0                  0   \n",
            "1597    0     0      0        0         0   0           0                  0   \n",
            "1598    0     0      0        0         0   0           0                  0   \n",
            "1599    0     0      0        0         0   0           0                  0   \n",
            "\n",
            "      00 way  00 way gone  ...  zephyr skin  zephyr skin time  zilla  \\\n",
            "0          0            0  ...            0                 0      0   \n",
            "1          0            0  ...            0                 0      0   \n",
            "2          0            0  ...            0                 0      0   \n",
            "3          0            0  ...            0                 0      0   \n",
            "4          0            0  ...            1                 1      0   \n",
            "...      ...          ...  ...          ...               ...    ...   \n",
            "1595       0            0  ...            0                 0      0   \n",
            "1596       0            0  ...            0                 0      0   \n",
            "1597       0            0  ...            0                 0      0   \n",
            "1598       0            0  ...            0                 0      0   \n",
            "1599       0            0  ...            0                 0      0   \n",
            "\n",
            "      zilla story  zip  zip tote  zip tote quickly  zombie  zombie apocalypse  \\\n",
            "0               0    0         0                 0       0                  0   \n",
            "1               0    0         0                 0       0                  0   \n",
            "2               0    0         0                 0       0                  0   \n",
            "3               0    0         0                 0       0                  0   \n",
            "4               0    0         0                 0       0                  0   \n",
            "...           ...  ...       ...               ...     ...                ...   \n",
            "1595            0    0         0                 0       0                  0   \n",
            "1596            0    0         0                 0       0                  0   \n",
            "1597            0    0         0                 0       0                  0   \n",
            "1598            0    0         0                 0       0                  0   \n",
            "1599            0    0         0                 0       0                  0   \n",
            "\n",
            "      zombie apocalypse beginning  \n",
            "0                               0  \n",
            "1                               0  \n",
            "2                               0  \n",
            "3                               0  \n",
            "4                               0  \n",
            "...                           ...  \n",
            "1595                            0  \n",
            "1596                            0  \n",
            "1597                            0  \n",
            "1598                            0  \n",
            "1599                            0  \n",
            "\n",
            "[1600 rows x 19883 columns]\n",
            "     Joy  Fear  Anger  Sadness  Surprise  00  00 started  00 started losing  \\\n",
            "0      0     0      0        0         0   0           0                  0   \n",
            "1      0     0      0        0         0   0           0                  0   \n",
            "2      0     0      0        0         0   0           0                  0   \n",
            "3      0     0      0        0         0   0           0                  0   \n",
            "4      0     0      0        0         0   0           0                  0   \n",
            "..   ...   ...    ...      ...       ...  ..         ...                ...   \n",
            "395    0     0      0        0         0   0           0                  0   \n",
            "396    0     0      0        0         0   0           0                  0   \n",
            "397    0     0      0        0         0   0           0                  0   \n",
            "398    0     0      0        0         0   0           0                  0   \n",
            "399    0     0      0        0         0   0           0                  0   \n",
            "\n",
            "     00 way  00 way gone  ...  zephyr skin  zephyr skin time  zilla  \\\n",
            "0         0            0  ...            0                 0      0   \n",
            "1         0            0  ...            0                 0      0   \n",
            "2         0            0  ...            0                 0      0   \n",
            "3         0            0  ...            0                 0      0   \n",
            "4         0            0  ...            0                 0      0   \n",
            "..      ...          ...  ...          ...               ...    ...   \n",
            "395       0            0  ...            0                 0      0   \n",
            "396       0            0  ...            0                 0      0   \n",
            "397       0            0  ...            0                 0      0   \n",
            "398       0            0  ...            0                 0      0   \n",
            "399       0            0  ...            0                 0      0   \n",
            "\n",
            "     zilla story  zip  zip tote  zip tote quickly  zombie  zombie apocalypse  \\\n",
            "0              0    0         0                 0       0                  0   \n",
            "1              0    0         0                 0       0                  0   \n",
            "2              0    0         0                 0       0                  0   \n",
            "3              0    0         0                 0       0                  0   \n",
            "4              0    0         0                 0       0                  0   \n",
            "..           ...  ...       ...               ...     ...                ...   \n",
            "395            0    0         0                 0       0                  0   \n",
            "396            0    0         0                 0       0                  0   \n",
            "397            0    0         0                 0       0                  0   \n",
            "398            0    0         0                 0       0                  0   \n",
            "399            0    0         0                 0       0                  0   \n",
            "\n",
            "     zombie apocalypse beginning  \n",
            "0                              0  \n",
            "1                              0  \n",
            "2                              0  \n",
            "3                              0  \n",
            "4                              0  \n",
            "..                           ...  \n",
            "395                            0  \n",
            "396                            0  \n",
            "397                            0  \n",
            "398                            0  \n",
            "399                            0  \n",
            "\n",
            "[400 rows x 19883 columns]\n",
            "F1 Score (macro): 0.2908153913515797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Using TFIDF Vectorizer\n",
        "\n",
        "# # Text Preprocessing using TfidfVectorizer\n",
        "# vectorizer = TfidfVectorizer(stop_words='english', max_features=15000)\n",
        "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "# X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# # One-vs-Rest for multilabel classification\n",
        "\n",
        "# # Naive Bayes\n",
        "# NB = OneVsRestClassifier(MultinomialNB())\n",
        "# NB.fit(X_train_tfidf, y_train)\n",
        "# NBprediction = NB.predict(X_test_tfidf)\n",
        "\n",
        "# # Logistic Regression\n",
        "# LR = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
        "# LR.fit(X_train_tfidf, y_train)\n",
        "# LRpredictions = LR.predict(X_test_tfidf)\n",
        "\n",
        "# # Random Forest\n",
        "# RF = OneVsRestClassifier(RandomForestClassifier(random_state=42))\n",
        "# RF.fit(X_train_tfidf, y_train)\n",
        "# RFpredictions = RF.predict(X_test_tfidf)\n",
        "\n",
        "# # SVM\n",
        "# SVM = OneVsRestClassifier(SVC())\n",
        "# SVM.fit(X_train_tfidf, y_train)\n",
        "# SVMpredictions = SVM.predict(X_test_tfidf)\n",
        "\n",
        "\n",
        "# # F1 Score\n",
        "# NB_f1 = f1_score(y_test, NBprediction,average='macro')\n",
        "# LR_f1 = f1_score(y_test, LRpredictions,average='macro')\n",
        "# RF_f1 = f1_score(y_test, RFpredictions,average='macro')\n",
        "# SVM_f1 = f1_score(y_test, SVMpredictions,average='macro')\n",
        "\n",
        "# print(\"Naive Bayes F1 Score (macro):\", NB_f1)\n",
        "# print(\"Logistic Regression F1 Score (macro):\", LR_f1)\n",
        "# print(\"Random Forest F1 Score (macro):\", RF_f1)\n",
        "# print(\"SVM F1 Score (macro):\", SVM_f1)"
      ],
      "metadata": {
        "id": "BWE0gvORuOZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Count Vectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=15000)\n",
        "X_train_count = vectorizer.fit_transform(X_train)\n",
        "X_test_count = vectorizer.transform(X_test)\n",
        "\n",
        "# # Naive Bayes\n",
        "# NB = OneVsRestClassifier(MultinomialNB())\n",
        "# NB.fit(X_train_count, y_train)\n",
        "# NBprediction = NB.predict(X_test_count)\n",
        "\n",
        "# # Logistic Regression\n",
        "# LR = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
        "# LR.fit(X_train_count, y_train)\n",
        "# LRpredictions = LR.predict(X_test_count)\n",
        "\n",
        "# Random Forest\n",
        "RF = OneVsRestClassifier(RandomForestClassifier(random_state=42))\n",
        "RF.fit(X_train_count, y_train)\n",
        "RFpredictions = RF.predict(X_test_count)\n",
        "\n",
        "# # SVM\n",
        "# SVM = OneVsRestClassifier(SVC())\n",
        "# SVM.fit(X_train_count, y_train)\n",
        "# SVMpredictions = SVM.predict(X_test_count)\n",
        "\n",
        "\n",
        "# F1 Score\n",
        "# NB_f1 = f1_score(y_test, NBprediction,average='macro')\n",
        "# LR_f1 = f1_score(y_test, LRpredictions,average='macro')\n",
        "RF_f1 = f1_score(y_test, RFpredictions,average='macro')\n",
        "# SVM_f1 = f1_score(y_test, SVMpredictions,average='macro')\n",
        "\n",
        "# print(\"Naive Bayes F1 Score (macro):\", NB_f1)\n",
        "# print(\"Logistic Regression F1 Score (macro):\", LR_f1)\n",
        "print(\"Random Forest F1 Score (macro):\", RF_f1)\n",
        "# print(\"SVM F1 Score (macro):\", SVM_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GKc1ct0SAic",
        "outputId": "18f9927a-f20f-47b4-9aeb-de4bc131aa57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest F1 Score (macro): 0.396847796201511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Macro F1 score for Random Forest is highest and using CountVectorizer(Bag of Words) Vector Transformation.(0.396)"
      ],
      "metadata": {
        "id": "nas2saoscoCB"
      }
    }
  ]
}